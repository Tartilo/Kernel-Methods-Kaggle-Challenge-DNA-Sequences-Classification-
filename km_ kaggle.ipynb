{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "from joblib import Parallel, delayed\n",
    "from tqdm import tqdm\n",
    "from collections import Counter\n",
    "from itertools import product\n",
    "from numba import prange\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kernel Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Substring Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_B_matrix(x, x_prime, k, lambda_decay):\n",
    "    \"\"\"Computes the B_k matrix with dynamic programming\"\"\"\n",
    "    n, m = len(x), len(x_prime)\n",
    "    B = np.zeros((k + 1, n + 1, m + 1))\n",
    "    B[0, :, :] = 1  # Base case\n",
    "\n",
    "    for l in range(1, k + 1):\n",
    "        for i in range(1, n + 1):\n",
    "            for j in range(1, m + 1):\n",
    "                if x[i - 1] == x_prime[j - 1]: \n",
    "                    B[l, i, j] = lambda_decay * (B[l, i - 1, j] + B[l, i, j - 1] - lambda_decay * B[l, i - 1, j - 1])\n",
    "                    B[l, i, j] += (lambda_decay ** 2) * B[l - 1, i - 1, j - 1]\n",
    "                else:\n",
    "                    B[l, i, j] = lambda_decay * (B[l, i - 1, j] + B[l, i, j - 1] - lambda_decay * B[l, i - 1, j - 1])\n",
    "    return B\n",
    "\n",
    "def substring_kernel(x, x_prime, k, lambda_decay):\n",
    "    \"\"\"Computes the substring kernel K_k with dynamic programming\"\"\"\n",
    "    n, m = len(x), len(x_prime)\n",
    "    \n",
    "    # Compute B_k\n",
    "    B = compute_B_matrix(x, x_prime, k, lambda_decay)\n",
    "\n",
    "    # Base cases\n",
    "    if k==0:\n",
    "        K = np.ones((n + 1, m + 1))\n",
    "    else:\n",
    "        K = np.zeros((n + 1, m + 1))\n",
    "\n",
    "    # Dynamic Programming\n",
    "    for i in range(1, n + 1):\n",
    "        K[i, :] = K[i - 1, :]\n",
    "\n",
    "        for j in range(1, m + 1):\n",
    "            res = 0\n",
    "            for j_prime in range(1,m+1):\n",
    "                if x_prime[j_prime-1] == x[i - 1]:\n",
    "                    res += B[k-1, i - 1, j_prime-1]\n",
    "            K[i, j] += (lambda_decay**2) * res\n",
    "\n",
    "    # Return the final kernel value\n",
    "    return K[n, m]  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Substring Kernel Value: 0.0625\n"
     ]
    }
   ],
   "source": [
    "# Example Usage\n",
    "x = \"CAT\"\n",
    "x_prime = \"BAT\"\n",
    "k = 2  # Substring length\n",
    "lambda_decay = 0.5\n",
    "\n",
    "kernel_value = substring_kernel(x, x_prime, k, lambda_decay)\n",
    "print(\"Substring Kernel Value:\", kernel_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spectrum Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_kmer_counts(seq, k):\n",
    "    \"\"\"Extracts k-mer counts from a DNA sequence.\"\"\"\n",
    "    return Counter([seq[i:i+k] for i in range(len(seq) - k + 1)])\n",
    "\n",
    "def spectrum_kernel(x, x_prime, k):\n",
    "    # Compute k-mer counts for both sequences\n",
    "    kmer_counts_x = get_kmer_counts(x, k)\n",
    "    kmer_counts_x_prime = get_kmer_counts(x_prime, k)\n",
    "\n",
    "    # Compute dot product of k-mer count vectors\n",
    "    return sum(kmer_counts_x[u] * kmer_counts_x_prime[u] for u in set(kmer_counts_x) & set(kmer_counts_x_prime))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectrum Kernel Value: 7\n"
     ]
    }
   ],
   "source": [
    "x = 'CARCARD'\n",
    "x_prime = 'BARARDAR'\n",
    "\n",
    "k = 2  # Example k-mer length\n",
    "\n",
    "kernel_value = spectrum_kernel(x, x_prime, k)\n",
    "print(\"Spectrum Kernel Value:\", kernel_value)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mismatch Kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hamming_distance(s1, s2):\n",
    "    \"\"\"Computes Hamming distance between two equal-length strings.\"\"\"\n",
    "    return sum(c1 != c2 for c1, c2 in zip(s1, s2))\n",
    "\n",
    "def generate_mismatch_kmers(kmer, m):\n",
    "    \"\"\"Generates all possible k-mers within `m` mismatches of a given k-mer.\"\"\"\n",
    "    bases = ['A', 'C', 'G', 'T']\n",
    "    mismatch_kmers = set([kmer])\n",
    "\n",
    "    for positions in product(range(len(kmer)), repeat=m):\n",
    "        for replacements in product(bases, repeat=m):\n",
    "            kmer_list = list(kmer)\n",
    "            for pos, replacement in zip(positions, replacements):\n",
    "                kmer_list[pos] = replacement\n",
    "            mismatch_kmers.add(\"\".join(kmer_list))\n",
    "\n",
    "    return mismatch_kmers\n",
    "\n",
    "def count_kmers_with_mismatches(sequence, k, m):\n",
    "    \"\"\"Counts k-mers in `sequence`, including up to `m` mismatches.\"\"\"\n",
    "    kmer_counts = {}\n",
    "\n",
    "    for i in range(len(sequence) - k + 1):\n",
    "        kmer = sequence[i:i+k]\n",
    "        mismatch_kmers = generate_mismatch_kmers(kmer, m)\n",
    "\n",
    "        for mismatch_kmer in mismatch_kmers:\n",
    "            if mismatch_kmer in kmer_counts:\n",
    "                kmer_counts[mismatch_kmer] += 1\n",
    "            else:\n",
    "                kmer_counts[mismatch_kmer] = 1\n",
    "\n",
    "    return kmer_counts\n",
    "\n",
    "def mismatch_kernel(x, x_prime, k, m):\n",
    "    # Count k-mers with mismatches\n",
    "    x_counts = count_kmers_with_mismatches(x, k, m)\n",
    "    x_prime_counts = count_kmers_with_mismatches(x_prime, k, m)\n",
    "\n",
    "    # Compute kernel similarity using dot product of k-mer counts\n",
    "    similarity = sum(x_counts[kmer] * x_prime_counts.get(kmer, 0) for kmer in x_counts)\n",
    "\n",
    "    return similarity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mismatch Kernel Similarity: 86\n"
     ]
    }
   ],
   "source": [
    "x = \"ACGTACGT\"\n",
    "x_prime = \"ACGGACGT\"\n",
    "k = 3   # 3-mers\n",
    "m = 1   # Allow 1 mismatch\n",
    "\n",
    "similarity = mismatch_kernel(x, x_prime, k, m)\n",
    "print(f\"Mismatch Kernel Similarity: {similarity}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the Kernel Matrix efficiently"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_matrix(K):\n",
    "    ''' We normalize the matrix for numerical stability'''\n",
    "    diag_K=np.diag(K)\n",
    "    root_K=np.sqrt(diag_K)\n",
    "    K_inv=np.diag(1/root_K)\n",
    "    return K_inv @ K @ K_inv\n",
    "\n",
    "def compute_kernel_matrix_parallel(X, k, m=None, lambda_decay = None, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Computes the Kernel matrix in parallel using joblib.\n",
    "    \"\"\"\n",
    "    n = len(X)\n",
    "    K = np.zeros((n, n))\n",
    "\n",
    "    # Generate index pairs for upper triangle computation\n",
    "    indices = [(i, j) for i in range(n) for j in range(i, n)]\n",
    "\n",
    "    if lambda_decay is not None:\n",
    "        # Compute kernel entries in parallel with tqdm\n",
    "        results = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(substring_kernel)(X[i], X[j], k, lambda_decay) for i, j in tqdm(indices, desc=\"Computing Substring Kernel Matrix\", unit=\" entry\")\n",
    "        )\n",
    "\n",
    "    elif m is not None:\n",
    "        # Compute kernel entries in parallel with tqdm\n",
    "        results = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(mismatch_kernel)(X[i], X[j], k, m) for i, j in tqdm(indices, desc=\"Computing Mismatch Kernel Matrix\", unit=\" entry\")\n",
    "        )\n",
    "\n",
    "    else:\n",
    "        # Compute kernel entries in parallel with tqdm\n",
    "        results = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(spectrum_kernel)(X[i], X[j], k) for i, j in tqdm(indices, desc=\"Computing Spectrum Kernel Matrix\", unit=\" entry\")\n",
    "        )\n",
    "        \n",
    "    # Fill the kernel matrix\n",
    "    index = 0\n",
    "    for i, j in indices:\n",
    "        K[i, j] = results[index]\n",
    "        index += 1\n",
    "\n",
    "    # Mirror the upper triangle to the lower triangle\n",
    "    K = K + K.T - np.diag(K.diagonal())  # Ensure symmetry\n",
    "\n",
    "    return normalize_matrix(K)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will test algorithm and compute different Kernel Matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Substring Kernel Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "k = 5\n",
    "lambda_decay = 0.5\n",
    "\n",
    "# Load training sequences\n",
    "X_train_0 = df_Xtr0.iloc[:, 1].tolist()\n",
    "\n",
    "K_train_0 = compute_kernel_matrix_parallel(X_train_0, k, lambda_decay = lambda_decay)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spectrum Kernel Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Spectrum Kernel Matrix: 100%|██████████| 2001000/2001000 [00:12<00:00, 165380.64 entry/s]\n"
     ]
    }
   ],
   "source": [
    "k = 8\n",
    "\n",
    "X_train_0 = df_Xtr0.iloc[:, 1].tolist()\n",
    "\n",
    "# Compute the kernel matrix in parallel\n",
    "K_train_0 = compute_kernel_matrix_parallel(X_train_0, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mismatch Kernel Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 8  # Choose k-mer length\n",
    "m= 1\n",
    "\n",
    "X_train = df_Xtr0.iloc[:, 1].tolist()\n",
    "\n",
    "K_train_mismatch_0 = compute_kernel_matrix_parallel(X_train, k,m = m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\hat{f}=\\argmin_{f\\in \\mathcal{H}} \\frac{1}{n}\\displaystyle\\sum_{i=1}^n \\ln(1+e^{-y_if(x_i)}) + \\frac{\\lambda}{2}\\Vert f\\Vert^2_{\\mathcal{H}}$\n",
    "\n",
    "By the representer theorem, $\\hat{f}(x)=\\displaystyle\\sum_{i=1}^n \\alpha_i K(x_i,x)$\n",
    "\n",
    "We therefore solve $\\min_{\\alpha\\in\\mathbb{R}^n}\\displaystyle\\sum_{i=1}^n \\ln(1+e^{-y_i[K\\alpha]_i})+ \\frac{\\lambda}{2}\\alpha^TK\\alpha$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kernel_logistic_loss(alpha, K, y, reg_lambda):\n",
    "    \"\"\"\n",
    "    Computes the objective function for kernel logistic regression.\n",
    "    \"\"\"\n",
    "    n = len(y)\n",
    "    K_alpha = K @ alpha  \n",
    "    \n",
    "    loss = np.sum(np.log(1 + np.exp(-y * K_alpha))) / n  \n",
    "    reg = (reg_lambda / 2) * (alpha @ K @ alpha)  \n",
    "    return loss + reg\n",
    "\n",
    "def kernel_logistic_gradient(alpha, K, y, reg_lambda):\n",
    "    \"\"\"\n",
    "    Computes the gradient of the kernel logistic loss.\n",
    "    \"\"\"\n",
    "    n = len(y)\n",
    "    K_alpha = K @ alpha\n",
    "    probs = 1 / (1 + np.exp(y * K_alpha))  \n",
    "\n",
    "    grad = - (K @ (y * probs)) / n  \n",
    "    grad += reg_lambda * (K @ alpha)  \n",
    "    return grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_kernel_logistic_regression(K, y, reg_lambda):\n",
    "    \"\"\"\n",
    "    Solves for α using gradient-based optimization.\n",
    "    \"\"\"\n",
    "    n = len(y)\n",
    "    alpha0 = np.zeros(n)  # Initialize α to zeros\n",
    "\n",
    "    # Use L-BFGS optimizer\n",
    "    result = minimize(kernel_logistic_loss, alpha0, \n",
    "                      args=(K, y, reg_lambda), \n",
    "                      jac=kernel_logistic_gradient,\n",
    "                      method='L-BFGS-B',\n",
    "                      options={'maxiter': 1000})\n",
    "\n",
    "    return result.x  # Optimized α values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_kernel_logistic_binary(alpha, X_train, X_test, k, m = None, lambda_decay=None, n_jobs=-1):\n",
    "    \"\"\"\n",
    "    Predicts binary labels using kernel logistic regression with parallel processing (for faster computation).\n",
    "    \"\"\"\n",
    "    n_test, n_train = len(X_test), len(X_train)\n",
    "    K_test = np.zeros((n_test, n_train))\n",
    "\n",
    "    indices = [(i, j) for i in range(n_test) for j in range(n_train)]\n",
    "\n",
    "    if lambda_decay is not None:\n",
    "        results = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(substring_kernel)(X_test[i], X_train[j], k, lambda_decay) \n",
    "            for i, j in tqdm(indices, desc=\"Computing Test-Train Substring Kernel\", unit=\" entry\")\n",
    "        )\n",
    "\n",
    "    elif m is not None:\n",
    "            results = Parallel(n_jobs=n_jobs)(\n",
    "                delayed(mismatch_kernel)(X_test[i], X_train[j], k, m) \n",
    "                for i, j in tqdm(indices, desc=\"Computing Test-Train Mismatch Kernel\", unit=\" entry\")\n",
    "            )\n",
    "    else:\n",
    "        results = Parallel(n_jobs=n_jobs)(\n",
    "            delayed(spectrum_kernel)(X_test[i], X_train[j], k) \n",
    "            for i, j in tqdm(indices, desc=\"Computing Test-Train Spectrum Kernel\", unit=\" entry\")\n",
    "        )\n",
    "\n",
    "    for index, (i, j) in enumerate(indices):\n",
    "        K_test[i, j] = results[index]\n",
    "\n",
    "    scores = K_test @ alpha  \n",
    "\n",
    "    return np.sign(scores)  # Convert to {-1,1} labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF - 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "df_Xtr0 = pd.read_csv('Xtr0.csv')\n",
    "df_Ytr0 = pd.read_csv('Ytr0.csv')\n",
    "\n",
    "df_Xte0 = pd.read_csv('Xte0.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to {-1,1} if they are in {0,1}\n",
    "df_Ytr0.iloc[:, 1] = 2 * df_Ytr0.iloc[:, 1] - 1 if df_Ytr0.iloc[:, 1].min() == 0 else df_Ytr0.iloc[:, 1]\n",
    "\n",
    "# Get the number of samples\n",
    "n = len(df_Xtr0)\n",
    "split_index = int(0.8 * n)  # 80% training, 20% validation\n",
    "\n",
    "# Shuffle indices\n",
    "indices = np.arange(n)\n",
    "np.random.seed(40)  # For reproducibility\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Apply shuffle to DataFrames\n",
    "df_Xtr0_shuffled = df_Xtr0.iloc[indices].reset_index(drop=True)\n",
    "df_Ytr0_shuffled = df_Ytr0.iloc[indices].reset_index(drop=True)\n",
    "\n",
    "# Split into train and validation DataFrames\n",
    "df_X_train_split = df_Xtr0_shuffled.iloc[:split_index]  # Training features\n",
    "df_Y_train_split = df_Ytr0_shuffled.iloc[:split_index]  # Training labels\n",
    "df_X_val = df_Xtr0_shuffled.iloc[split_index:]  # Validation features\n",
    "df_Y_val = df_Ytr0_shuffled.iloc[split_index:]  # Validation labels\n",
    "\n",
    "print(f\"Training set size: {len(df_X_train_split)}, Validation set size: {len(df_X_val)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_X_train_split.iloc[:, 1].tolist()\n",
    "y_train = df_Y_train_split.iloc[:, 1].values\n",
    "\n",
    "X_val = df_X_val.iloc[:, 1].tolist()\n",
    "y_val = df_Y_val.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Validation Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Spectrum Kernel Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 8  # Choose length of substring\n",
    "\n",
    "# Compute Spectrum Kernel Matrix\n",
    "K_train_spectrum_0 = compute_kernel_matrix_parallel(X_train, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Substring Kernel Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "k = 4\n",
    "lambda_decay = 0.5\n",
    "n_jobs = -1  # Use all available CPU cores\n",
    "\n",
    "# Load training sequences\n",
    "X_train_0 = df_Xtr0.iloc[:, 1].tolist()\n",
    "\n",
    "K_train_0 = compute_kernel_matrix_parallel(X_train_0, k, lambda_decay, n_jobs=n_jobs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Mismatch Kernel Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 8  # Choose length of substring\n",
    "m=1\n",
    "\n",
    "# Compute Spectrum Kernel Matrix\n",
    "K_train_mismatch_0 = compute_kernel_matrix_parallel(X_train, k, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = K_train_mismatch_0\n",
    "\n",
    "reg_lambda = 1e-5 # Regularization parameter\n",
    "\n",
    "# Train model\n",
    "alpha = train_kernel_logistic_regression(K, y_train, reg_lambda)\n",
    "\n",
    "# Compute train accuracy\n",
    "y_pred = np.sign(K @ alpha)  # Predict labels\n",
    "train_accuracy = np.mean(y_pred == y_train)  \n",
    "print(f'Train accuracy: {train_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute validation kernel matrix (K_val)\n",
    "y_pred = predict_kernel_logistic_binary(alpha, X_train, X_val, k, m = m)\n",
    "\n",
    "val_accuracy = np.mean(y_pred == y_val) \n",
    "print(f'Validation accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with Full Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_Xtr0.iloc[:, 1].tolist()\n",
    "y_train = df_Ytr0.iloc[:, 1].values\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comptute Spectrum Kernel Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 8  # Choose length of substring\n",
    "\n",
    "# Compute Spectrum Kernel Matrix\n",
    "K_train_spectrum_0 = compute_kernel_matrix(X_train, k)\n",
    "\n",
    "np.save(\"spectrum_kernel_matrix_0.npy\", K_train_spectrum_0)\n",
    "print(\"Spectrum Kernel Matrix computed and saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = K_train_spectrum_0\n",
    "\n",
    "reg_lambda = 1e-5 # Regularization parameter\n",
    "\n",
    "# Train model\n",
    "alpha = train_kernel_logistic_regression(K, y_train, reg_lambda)\n",
    "\n",
    "# Compute train accuracy\n",
    "y_pred = np.sign(K @ alpha)  # Predict labels\n",
    "train_accuracy = np.mean(y_pred == y_train)  \n",
    "print(f'Train accuracy: {train_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "X_test = df_Xte0.iloc[:, 1].tolist()  # Test sequences\n",
    "\n",
    "# Predict probabilities for test set\n",
    "y_test_probs = predict_kernel_logistic_binary(alpha, X_train, X_test, k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_probs = ((y_test_probs + 1) / 2).astype(int)  # Convert {-1,1} to {0,1}\n",
    "\n",
    "#save as csv file\n",
    "\n",
    "df_Yte0 = pd.DataFrame(data = y_test_probs, columns = ['Bound'])\n",
    "df_Yte0.index.name = 'Id'\n",
    "df_Yte0.to_csv('Yte0.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Mismatch Kernel Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 8  # Choose length of substring\n",
    "m=1\n",
    "\n",
    "# Compute Spectrum Kernel Matrix\n",
    "K_train_mismatch_0 = compute_kernel_matrix_parallel(X_train, k, m)\n",
    "\n",
    "np.save(\"mismatch_kernel_matrix_0.npy\", K_train_mismatch_0)\n",
    "print(\"Spectrum Kernel Matrix computed and saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = K_train_mismatch_0\n",
    "\n",
    "reg_lambda = 1e-5 # Regularization parameter\n",
    "\n",
    "# Train model\n",
    "alpha = train_kernel_logistic_regression(K, y_train, reg_lambda)\n",
    "\n",
    "# Compute train accuracy\n",
    "y_pred = np.sign(K @ alpha)  # Predict labels\n",
    "train_accuracy = np.mean(y_pred == y_train)  # Compute accuracy\n",
    "print(f'Train accuracy: {train_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "X_test = df_Xte0.iloc[:, 1].tolist()  # Test sequences\n",
    "\n",
    "# Predict probabilities for test set\n",
    "y_test_probs = predict_kernel_logistic_binary(alpha, X_train, X_test, k)\n",
    "y_test_probs = ((y_test_probs + 1) / 2).astype(int)  # Convert {-1,1} to {0,1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as csv file\n",
    "\n",
    "df_Yte0 = pd.DataFrame(data = y_test_probs, columns = ['Bound'])\n",
    "df_Yte0.index.name = 'Id'\n",
    "df_Yte0.to_csv('Yte0.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data\n",
    "# load the data\n",
    "df_Xtr1 = pd.read_csv('Xtr1.csv')\n",
    "df_Ytr1 = pd.read_csv('Ytr1.csv')\n",
    "\n",
    "df_Xte1 = pd.read_csv('Xte1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 1600, Validation set size: 400\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to {-1,1} if they are in {0,1}\n",
    "df_Ytr1.iloc[:, 1] = 2 * df_Ytr1.iloc[:, 1] - 1 if df_Ytr1.iloc[:, 1].min() == 0 else df_Ytr1.iloc[:, 1]\n",
    "\n",
    "# Get the number of samples\n",
    "n = len(df_Xtr1)\n",
    "split_index = int(0.8 * n)  # 80% training, 20% validation\n",
    "\n",
    "# Shuffle indices\n",
    "indices = np.arange(n)\n",
    "np.random.seed(42)  # For reproducibility\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Apply shuffle to DataFrames\n",
    "df_Xtr1_shuffled = df_Xtr1.iloc[indices].reset_index(drop=True)\n",
    "df_Ytr1_shuffled = df_Ytr1.iloc[indices].reset_index(drop=True)\n",
    "\n",
    "# Split into train and validation DataFrames\n",
    "df_X_train_split = df_Xtr1_shuffled.iloc[:split_index]  # Training features\n",
    "df_Y_train_split = df_Ytr1_shuffled.iloc[:split_index]  # Training labels\n",
    "df_X_val = df_Xtr1_shuffled.iloc[split_index:]  # Validation features\n",
    "df_Y_val = df_Ytr1_shuffled.iloc[split_index:]  # Validation labels\n",
    "\n",
    "print(f\"Training set size: {len(df_X_train_split)}, Validation set size: {len(df_X_val)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_X_train_split.iloc[:, 1].tolist()\n",
    "y_train = df_Y_train_split.iloc[:, 1].values\n",
    "\n",
    "X_val = df_X_val.iloc[:, 1].tolist()\n",
    "y_val = df_Y_val.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Validation Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Spectrum Kernel Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Spectrum Kernel Matrix: 100%|██████████| 1280800/1280800 [00:07<00:00, 179645.63 entry/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spectrum Kernel Matrix computed and saved successfully!\n"
     ]
    }
   ],
   "source": [
    "k = 8  # Choose length of substring\n",
    "\n",
    "# Compute Spectrum Kernel Matrix\n",
    "K_train_spectrum_1 = compute_kernel_matrix_parallel(X_train, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Mismatch Kernel Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Mismatch Kernel Matrix: 100%|██████████| 1280800/1280800 [10:39<00:00, 2001.97 entry/s]\n"
     ]
    }
   ],
   "source": [
    "k = 8  # Choose length of substring\n",
    "m=1\n",
    "\n",
    "# Compute Spectrum Kernel Matrix\n",
    "K_train_mismatch_1 = compute_kernel_matrix_parallel(X_train, k, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "K = K_train_mismatch_1\n",
    "\n",
    "reg_lambda = 1e-5 # Regularization parameter\n",
    "\n",
    "# Train model\n",
    "alpha = train_kernel_logistic_regression(K, y_train, reg_lambda)\n",
    "\n",
    "# Compute train accuracy\n",
    "\n",
    "y_pred = np.sign(K @ alpha)  # Predict labels\n",
    "train_accuracy = np.mean(y_pred == y_train)  # Compute accuracy\n",
    "print(f'Train accuracy: {train_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing Mismatch Kernel Matrix:   1%|▏         | 18415/1280800 [12:44<14:33:56, 24.07 entry/s]y/s]\n",
      "Computing Test-Train Spectrum Kernel: 100%|██████████| 640000/640000 [00:03<00:00, 181353.07 entry/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy: 0.7000\n"
     ]
    }
   ],
   "source": [
    "# Compute validation kernel matrix (K_val)\n",
    "y_pred = predict_kernel_logistic_binary(alpha, X_train, X_val, k, lambda_decay = None)\n",
    "\n",
    "val_accuracy = np.mean(y_pred == y_val)  # Compute accuracy\n",
    "print(f'Validation accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train with full Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_Xtr1.iloc[:, 1].tolist()\n",
    "y_train = df_Ytr1.iloc[:, 1].values\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Substring Kernel Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comptute Spectrum Kernel Matrix\n",
    "k = 8  # Choose length of substring\n",
    "\n",
    "# Compute Spectrum Kernel Matrix\n",
    "K_train_spectrum_1 = compute_kernel_matrix_parallel(X_train, k)\n",
    "\n",
    "np.save(\"spectrum_kernel_matrix_1.npy\", K_train_spectrum_1)\n",
    "print(\"Spectrum Kernel Matrix computed and saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = K_train_spectrum_1\n",
    "\n",
    "reg_lambda = 1e-5 # Regularization parameter\n",
    "\n",
    "# Train model\n",
    "alpha = train_kernel_logistic_regression(K, y_train, reg_lambda)\n",
    "\n",
    "# Compute train accuracy\n",
    "y_pred = np.sign(K @ alpha)  # Predict labels\n",
    "train_accuracy = np.mean(y_pred == y_train)  # Compute accuracy\n",
    "print(f'Train accuracy: {train_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "X_test = df_Xte1.iloc[:, 1].tolist()  # Test sequences\n",
    "\n",
    "# Predict probabilities for test set\n",
    "y_test_probs = predict_kernel_logistic_binary(alpha, X_train, X_test, k)\n",
    "y_test_probs = ((y_test_probs + 1) / 2).astype(int)  # Convert {-1,1} to {0,1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as csv file\n",
    "\n",
    "df_Yte1 = pd.DataFrame(data = y_test_probs, columns = ['Bound'])\n",
    "df_Yte1.index.name = 'Id'\n",
    "df_Yte1.to_csv('Yte1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Mismatch Kernel Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 8  # Choose length of substring\n",
    "m=1\n",
    "\n",
    "# Compute Spectrum Kernel Matrix\n",
    "K_train_mismatch_1 = compute_kernel_matrix_parallel(X_train, k, m)\n",
    "\n",
    "np.save(\"mismatch_kernel_matrix_1.npy\", K_train_mismatch_1)\n",
    "print(\"Spectrum Kernel Matrix computed and saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = K_train_mismatch_1\n",
    "\n",
    "reg_lambda = 1e-5 # Regularization parameter\n",
    "\n",
    "# Train model\n",
    "alpha = train_kernel_logistic_regression(K, y_train, reg_lambda)\n",
    "\n",
    "# Compute train accuracy\n",
    "y_pred = np.sign(K @ alpha)  # Predict labels\n",
    "train_accuracy = np.mean(y_pred == y_train)  # Compute accuracy\n",
    "print(f'Train accuracy: {train_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "X_test = df_Xte1.iloc[:, 1].tolist()  # Test sequences\n",
    "\n",
    "# Predict probabilities for test set\n",
    "y_test_probs = predict_kernel_logistic_binary(alpha, X_train, X_test, k)\n",
    "y_test_probs = ((y_test_probs + 1) / 2).astype(int)  # Convert {-1,1} to {0,1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as csv file\n",
    "\n",
    "df_Yte1 = pd.DataFrame(data = y_test_probs, columns = ['Bound'])\n",
    "df_Yte1.index.name = 'Id'\n",
    "df_Yte1.to_csv('Yte0.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF - 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "df_Xtr2 = pd.read_csv('Xtr2.csv')\n",
    "df_Ytr2 = pd.read_csv('Ytr2.csv')\n",
    "\n",
    "df_Xte2 = pd.read_csv('Xte2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert labels to {-1,1} if they are in {0,1}\n",
    "df_Ytr2.iloc[:, 1] = 2 * df_Ytr2.iloc[:, 1] - 1 if df_Ytr2.iloc[:, 1].min() == 0 else df_Ytr2.iloc[:, 1]\n",
    "\n",
    "# Get the number of samples\n",
    "n = len(df_Xtr2)\n",
    "split_index = int(0.8 * n)  # 80% training, 20% validation\n",
    "\n",
    "# Shuffle indices\n",
    "indices = np.arange(n)\n",
    "np.random.seed(42)  # For reproducibility\n",
    "np.random.shuffle(indices)\n",
    "\n",
    "# Apply shuffle to DataFrames\n",
    "df_Xtr2_shuffled = df_Xtr2.iloc[indices].reset_index(drop=True)\n",
    "df_Ytr2_shuffled = df_Ytr2.iloc[indices].reset_index(drop=True)\n",
    "\n",
    "\n",
    "# Split into train and validation DataFrames\n",
    "df_X_train_split = df_Xtr2_shuffled.iloc[:split_index]  # Training features\n",
    "df_Y_train_split = df_Ytr2_shuffled.iloc[:split_index]  # Training labels\n",
    "df_X_val = df_Xtr2_shuffled.iloc[split_index:]  # Validation features\n",
    "df_Y_val = df_Ytr2_shuffled.iloc[split_index:]  # Validation labels\n",
    "\n",
    "print(f\"Training set size: {len(df_X_train_split)}, Validation set size: {len(df_X_val)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_X_train_split.iloc[:, 1].tolist()\n",
    "y_train = df_Y_train_split.iloc[:, 1].values\n",
    "\n",
    "X_val = df_X_val.iloc[:, 1].tolist()\n",
    "y_val = df_Y_val.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train/Validatin Split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Spectrum Kernel Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 8  # Choose length of substring\n",
    "\n",
    "# Compute Spectrum Kernel Matrix\n",
    "K_train_spectrum_2 = compute_kernel_matrix(X_train, k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Mismatch Kernel Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 8  # Choose length of substring\n",
    "m=1\n",
    "\n",
    "# Compute Spectrum Kernel Matrix\n",
    "K_train_mismatch_2 = compute_kernel_matrix_parallel(X_train, k, m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = K_train_mismatch_2\n",
    "\n",
    "reg_lambda = 1e-5 # Regularization parameter\n",
    "\n",
    "# Train model\n",
    "alpha = train_kernel_logistic_regression(K, y_train, reg_lambda)\n",
    "\n",
    "# Compute train accuracy\n",
    "y_pred = np.sign(K @ alpha)  # Predict labels\n",
    "train_accuracy = np.mean(y_pred == y_train)  # Compute accuracy\n",
    "print(f'Train accuracy: {train_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute validation kernel matrix (K_val)\n",
    "y_pred = predict_kernel_logistic_binary(alpha, X_train, X_val, k, m = m)\n",
    "\n",
    "val_accuracy = np.mean(y_pred == y_val)  # Compute accuracy\n",
    "print(f'Validation accuracy: {val_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train on Full Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_Xtr2.iloc[:, 1].tolist()\n",
    "y_train = df_Ytr2.iloc[:, 1].values\n",
    "\n",
    "print(f\"Training set size: {len(X_train)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Spectrum Kernel Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comptute Spectrum Kernel Matrix\n",
    "k = 7  # Choose length of substring\n",
    "\n",
    "# Compute Spectrum Kernel Matrix\n",
    "K_train_spectrum_2 = compute_kernel_matrix(X_train, k)\n",
    "\n",
    "np.save(\"spectrum_kernel_matrix_2.npy\", K_train_spectrum_2)\n",
    "print(\"Spectrum Kernel Matrix computed and saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = K_train_spectrum_2\n",
    "\n",
    "reg_lambda = 1e-6 # Regularization parameter\n",
    "\n",
    "# Train model\n",
    "alpha = train_kernel_logistic_regression(K, y_train, reg_lambda)\n",
    "\n",
    "# Compute train accuracy\n",
    "y_pred = np.sign(K @ alpha)  # Predict labels\n",
    "train_accuracy = np.mean(y_pred == y_train)  # Compute accuracy\n",
    "print(f'Train accuracy: {train_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "X_test = df_Xte2.iloc[:, 1].tolist()  # Test sequences\n",
    "\n",
    "# Predict probabilities for test set\n",
    "y_test_probs = predict_kernel_logistic_binary(alpha, X_train, X_test, k)\n",
    "y_test_probs = ((y_test_probs + 1) / 2).astype(int)  # Convert {-1,1} to {0,1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Yte2 = pd.DataFrame(data = y_test_probs, columns = ['Bound'])\n",
    "df_Yte2.index.name = 'Id'\n",
    "df_Yte2.to_csv('Yte2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compute Mismatch Kernel Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 8  # Choose length of substring\n",
    "m=1\n",
    "\n",
    "# Compute Spectrum Kernel Matrix\n",
    "K_train_mismatch_2 = compute_kernel_matrix_parallel(X_train, k, m)\n",
    "\n",
    "np.save(\"mismatch_kernel_matrix_2.npy\", K_train_mismatch_2)\n",
    "print(\"Spectrum Kernel Matrix computed and saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = K_train_mismatch_2\n",
    "\n",
    "reg_lambda = 1e-5 # Regularization parameter\n",
    "\n",
    "# Train model\n",
    "alpha = train_kernel_logistic_regression(K, y_train, reg_lambda)\n",
    "\n",
    "# Compute train accuracy\n",
    "y_pred = np.sign(K @ alpha)  # Predict labels\n",
    "train_accuracy = np.mean(y_pred == y_train)  # Compute accuracy\n",
    "print(f'Train accuracy: {train_accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "X_test = df_Xte2.iloc[:, 1].tolist()  # Test sequences\n",
    "\n",
    "# Predict probabilities for test set\n",
    "y_test_probs = predict_kernel_logistic_binary(alpha, X_train, X_test, k)\n",
    "y_test_probs = ((y_test_probs + 1) / 2).astype(int)  # Convert {-1,1} to {0,1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save as csv file\n",
    "\n",
    "df_Yte2 = pd.DataFrame(data = y_test_probs, columns = ['Bound'])\n",
    "df_Yte2.index.name = 'Id'\n",
    "df_Yte2.to_csv('Yte2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load the data\n",
    "\n",
    "df_Yte0 = pd.read_csv('Yte0.csv')\n",
    "df_Yte1 = pd.read_csv('Yte1.csv')\n",
    "df_Yte2 = pd.read_csv('Yte2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate the results but fix the ids\n",
    "\n",
    "df_Yte = pd.concat([df_Yte0, df_Yte1, df_Yte2])\n",
    "df_Yte.Id = np.arange(len(df_Yte))\n",
    "#df_Yte.index.name = 'Id'\n",
    "df_Yte.to_csv('Yte.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Yte"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
